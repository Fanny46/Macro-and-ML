############################################################
# 0. Packages et options
############################################################

library(dplyr)
library(readr)
library(randomForest)
library(stats)

set.seed(123)

############################################################
# 1. Import et nettoyage des données
############################################################

data <- read_csv("2025-11-MD.csv", show_col_types = FALSE)

# Suppression de la première ligne (méta-données)
data <- data[-1, ]

# Conversion numérique (sauf date)
data[-1] <- lapply(data[-1], as.numeric)

# Suppression des NA
df <- na.omit(data)

# Suppression de la date pour le ML
df <- df %>% select(-sasdate)

############################################################
# 2. Création des transformations du CPI
############################################################

df <- df %>%
  arrange(row_number()) %>%
  mutate(
    dCPI = CPIAUCSL - lag(CPIAUCSL),
    infl = 100 * (log(CPIAUCSL) - log(lag(CPIAUCSL)))
  ) %>%
  na.omit()

############################################################
# 3. Paramètres de prévision
############################################################

h <- 3   # horizon
p <- 6   # nombre de retards

############################################################
# 4. Fonctions utilitaires
############################################################

# Création des lags et de la cible future
prepare_ml_data <- function(df, y_var, h, p) {
  
  df_ml <- df
  df_ml$y_lead <- dplyr::lead(df_ml[[y_var]], h)
  
  all_vars <- setdiff(names(df_ml), c("y_lead", y_var))
  
  for (var in all_vars) {
    for (lag in 1:p) {
      df_ml[[paste0(var, "_L", lag)]] <- dplyr::lag(df_ml[[var]], lag)
    }
  }
  
  df_ml <- df_ml %>%
    select(-all_of(all_vars)) %>%
    na.omit()
  
  return(df_ml)
}

# Séparation temporelle train / test
train_test_split <- function(df_ml, train_ratio = 0.8) {
  
  n <- nrow(df_ml)
  train_size <- floor(train_ratio * n)
  
  X <- df_ml %>% select(-y_lead)
  y <- df_ml$y_lead
  
  list(
    X_train = X[1:train_size, ],
    y_train = y[1:train_size],
    X_test  = X[(train_size + 1):n, ],
    y_test  = y[(train_size + 1):n],
    train_size = train_size
  )
}

# Fonctions de performance
rmse <- function(y, y_hat) sqrt(mean((y - y_hat)^2))
r2   <- function(y, y_hat) cor(y, y_hat)^2

############################################################
# 5. Préparation des jeux de données
############################################################

df_rf_level   <- prepare_ml_data(df, "CPIAUCSL", h, p)
df_rf_diff    <- prepare_ml_data(df, "dCPI", h, p)
df_rf_logdiff <- prepare_ml_data(df, "infl", h, p)

split_level   <- train_test_split(df_rf_level)
split_diff    <- train_test_split(df_rf_diff)
split_logdiff <- train_test_split(df_rf_logdiff)

############################################################
# 6. Modèles
############################################################

### 6.1 Random Forest – niveau

rf_level <- randomForest(
  x = split_level$X_train,
  y = split_level$y_train,
  ntree = 500,
  mtry = floor(sqrt(ncol(split_level$X_train)))
)

y_pred_rf_level <- predict(rf_level, split_level$X_test)

############################################################

### 6.2 Random Forest – différencié

rf_diff <- randomForest(
  x = split_diff$X_train,
  y = split_diff$y_train,
  ntree = 500,
  mtry = floor(sqrt(ncol(split_diff$X_train)))
)

dCPI_pred <- predict(rf_diff, split_diff$X_test)

# Reconstruction du CPI
CPI_last_diff <- df$CPIAUCSL[
  split_diff$train_size + p + h
]

CPI_pred_rf_diff <- CPI_last_diff + cumsum(dCPI_pred)

############################################################

### 6.3 Random Forest – log-différences (inflation)

rf_logdiff <- randomForest(
  x = split_logdiff$X_train,
  y = split_logdiff$y_train,
  ntree = 500,
  mtry = floor(sqrt(ncol(split_logdiff$X_train)))
)

infl_pred <- predict(rf_logdiff, split_logdiff$X_test)

# Reconstruction du CPI
CPI_last_logdiff <- df$CPIAUCSL[
  split_logdiff$train_size + p + h
]

CPI_pred_rf_logdiff <- CPI_last_logdiff * exp(cumsum(infl_pred) / 100)

############################################################

### 6.4 AR(1) benchmark

ar1_model <- arima(
  split_level$y_train,
  order = c(1, 0, 0)
)

y_pred_ar1 <- predict(
  ar1_model,
  n.ahead = length(split_level$y_test)
)$pred

############################################################
# 7. Évaluation (sur le niveau du CPI)
############################################################

CPI_true <- split_level$y_test

results <- data.frame(
  Modèle = c(
    "RF niveau",
    "RF différencié",
    "RF log-diff",
    "AR(1)"
  ),
  RMSE = c(
    rmse(CPI_true, y_pred_rf_level),
    rmse(CPI_true, CPI_pred_rf_diff),
    rmse(CPI_true, CPI_pred_rf_logdiff),
    rmse(CPI_true, y_pred_ar1)
  ),
  R2 = c(
    r2(CPI_true, y_pred_rf_level),
    r2(CPI_true, CPI_pred_rf_diff),
    r2(CPI_true, CPI_pred_rf_logdiff),
    r2(CPI_true, y_pred_ar1)
  )
)

print(results)
