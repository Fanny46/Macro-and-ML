# Diffusion indices - Anna Simoni

library(BVAR)
## Warning: le package 'BVAR' a été co+mpilé avec la version R 4.5.2
library(fbi)
library(glmnet)
## Warning: le package 'glmnet' a été compilé avec la version R 4.5.2
## Le chargement a nécessité le package : Matrix
## Loaded glmnet 4.1-10
library(xtable)
## Warning: le package 'xtable' a été compilé avec la version R 4.5.1
library(readr)
## Warning: le package 'readr' a été compilé avec la version R 4.5.2

## File name of desired FRED-MD vintage ##
#filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
#data <- fredmd(filepath, date_start = as.Date("1960-01-01"), date_end = NULL, transform = TRUE)       ##
data <- read_csv("2025-09-MD.csv", show_col_types = FALSE)
# The data are already transformed
# =========================================================================

# Type of transformation performed on each series before factors are
# estimated
#   0 --> no transformation
#   1 --> demean only
#   2 --> demean and standardize
#   3 --> recursively demean and then standardize
DEMEAN <- 2

# Information criterion used to select the number of factors; for more details,
# see auxiliary function factors_em()
#   1 --> information criterion PC_p1
#   2 --> information criterion PC_p2
#   3 --> information criterion PC_p3
jj <- 2

# Maximum number of factors to be estimated; if set to 99, the number of
# factors selected is forced to equal 3
kmax <- 99

# Select the variables to predict
# 6   : Industrial production (IP)
nn <- 6
HH = 12; # number of step ahead to forecast
# =========================================================================
# PART 1: LOAD AND LABEL DATA

# Variable names
series <- colnames(data[,2:length(data)])

# Raw data
rawdata <- data[2:nrow(data),2:length(data)]

# Month/year of the final observation
final_date <- tail(data$sasdate, 1)
dates <- data$sasdate

# T = number of months in the sample
T <- length(dates)

# Starting dates for the out-of-sample evaluation
start_date = "1/1/1974";
# =========================================================================
# PART 2: PROCESS DATA

# 1. Prepare Missing Data
yt <- rawdata

# 2. Reduce Sample  to usable dates: remove first two months because some
# series have been first differenced
dates <- dates[2:length(dates)]
dim_yt <- dim(yt)
TT <- dim_yt[1]
NN <- dim_yt[2]

# 3. Remove Outliers
result <- remove_outliers(yt)
# =========================================================================
start_sample <- which(dates == start_date)

# Number of time points to use in the estimation of the parameter: Rolling scheme
Jwind = start_sample

if (Jwind > start_sample) {
  stop("the rolling window cannot be larger than the first evaluation sample")
}

j0 <- start_sample - Jwind + 1

x_temp <- yt[j0:start_sample, ]   # The available data at the beginning of the out-of-sample evaluation exercise
x<- remove_outliers(x_temp)       # Remove outliers specific to this particular sample

# Prepare empty matrices that contain the results
# Set the parameters for Ridge
INfit = 0.5;       # Proportion of in-sample fit to be explained by ridge

# Performs the out-of-sample forecasting exercise
# Prepare empty matrices that contain the results
true <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
RW <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
PC <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
Ridge <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
Lasso <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
for (j in start_sample:(TT - tail(HH, 1) - 1)) {
                      # Remark that TT - tail(HH, 1) is '2014-04-01'. This is the last period ofthe out-of-sample
                      # start_sample + 1

  ## Displays the dates at the beginning of each month
  cat('--------------\n')
  cat('now running\n')
  cat(paste(dates[j], collapse = ' '), '\n')


  ## Define the beginning of the estimation sample
  j0 <- j - Jwind + 1  # Starting period for the in-sample

  x_temp <- yt[j0:j, ]  # The available data at each time point of the evaluation exercise
  x<- remove_outliers(x_temp)

  for (k in seq_along(nn)) {  # Loop across series to forecast

    for (h in HH) {  # Loop across the number of steps ahead

      ## Normalization constants
      if (nn[k] %in% c(1, 6, 25)) {
        const <- 12
      } else {
        const <- h
      }

      ## [1] Compute the true value to be predicted
      temp <- colMeans(yt[(j + 1):(j + h), nn[k]])
      true[j - Jwind + 1, k] <- temp * const

      ## [2] Compute the Constant growth forecast
      # Apply moving average filter
      Y <- stats::filter(x$INDPRO, filter = rep(1/h, h), sides = 1)
      # Discard the initial h elements
      Y2 <- Y[(h + 1):length(Y)]
      temp <- mean(Y2)
      RW[j - Jwind + 1, k] <- temp * const

      ## [3] Computes the Factor-based forecasts
      x_pred <- x[,-6]
      result_factors <- factors_em_2(x_pred, kmax, jj, DEMEAN)
      # Regressors
      Z <- cbind(1, result_factors$Fhat)
      # Compute the dependent variable to be predicted
      # Apply moving average filter: Y = (y_{+1}+...+y_{+h})/h
      Y <- stats::filter(x$INDPRO, filter = rep(1/h, h), sides = 1)
      # Compute the forecasts
      Z_trimmed <- Z[1:(nrow(Z)-h), ]
      gamma <- solve(t(Z_trimmed) %*% Z_trimmed) %*% t(Z_trimmed) %*% Y[(h+1):length(Y)]
      pred <- tail(Z, 1) %*% gamma

      PC[j - Jwind + 1, k] <- const * pred

      ## [4] Computes the Ridge-based forecasts
      #nu_ridge = SET_ridge(x,INfit)
      nu_ridge <- INfit
      result_Ridge <- Ridge_regression(x$INDPRO, x[,-6], nu_ridge, DEMEAN)
      Ridge[j - Jwind + 1, k] <- const * result_Ridge$pred
      
      ## [5] Computes the Lasso-based forecasts
      result_Lasso <- Lasso_regression(x$INDPRO, x[,-6], DEMEAN)
      Lasso[j - Jwind + 1, k] <- const * result_Lasso$pred
      
    }
  }
}
# Compute MSFE_RW and MSFE_PC
dates_OOS <- dates[(start_sample + 1):(length(dates)-h)]

true_NA <- na.omit(true[,1])
Index_NA <- which(is.na(true[,1]))
#dates_sub <- dates[j0:end]
#dates_NA <- dates_sub[,-Index_NA]
RW_NA <- na.omit(RW[,1])
PC_NA <- na.omit(PC[,1])
Ridge_NA <- na.omit(Ridge[,1])
Lasso_NA <- na.omit(Lasso[,1])
#MSFE
MSFE_RW <- sqrt(mean((true_NA - RW_NA)^2))
MSFE_PC <- sqrt(mean((true_NA - PC_NA)^2))
MSFE_Ridge <- sqrt(mean((true_NA - Ridge_NA)^2))
MSFE_Lasso <- sqrt(mean((true_NA - Lasso_NA)^2))
# MAE
MAE_RW <- mean(abs(true_NA - RW_NA))
MAE_PC <- mean(abs(true_NA - PC_NA))
MAE_Ridge <- mean(abs(true_NA - Ridge_NA))
MAE_Lasso <- mean(abs(true_NA - Lasso_NA))

tab <- data.frame(
  Method = c("PC","Ridge","Lasso"),
  MSFE = c(MSFE_PC/MSFE_RW,MSFE_Ridge/MSFE_RW,MSFE_Lasso/MSFE_RW),
  MAE = c(MAE_PC/MAE_RW,MAE_Ridge/MAE_RW,MAE_Lasso/MAE_RW)#,
#  MDA = c(mda_test_FPC_mean,mda_test_PR_F_mean,mda_test_PR_splines_mean,mda_test_midas_ALMON_mean,mda_test_midas_BETA_mean)
)

tab
df <- data.frame(dates = dates_OOS, values = true_NA)
ggplot(df, aes(x = dates, y = values)) +
     geom_line(color = "black") +
     labs(x = "Date", y = "Value") +
     theme_minimal()

plot(true_NA,
     type = 'l', col = "black")

points(RW_NA, col="red", lty=1)
lines(PC_NA, col="blue",lty=2)
lines(Ridge_NA, col="green",lty=1)
lines(Lasso_NA, col="pink",lty=1)

#--------------------------------------------------------------------------------------

######################################
#### FUNCTION Ridge_regression ####
######################################
Ridge_regression <- function(yy,x, nu,DEMEAN) {
  #x <- XX[,-6]                # Matrix containing the predictors
  # Apply moving average filter: Y = (y_{+1}+...+y_{+h})/h
  Y <- stats::filter(yy, filter = rep(1/h, h), sides = 1)   # Dependent variable
  
  
    # PART 1: CHECKS
  # Check that x is not missing values for an entire row
  if (any(rowSums(is.na(x)) == ncol(x))) {
    stop("Input x contains entire row of missing values.")
  }
  
  # Check that x is not missing values for an entire column
  if (any(colSums(is.na(x)) == nrow(x)) || any(colSums(is.na(x)) == (nrow(x)-1))) {
    #stop("Input x contains entire column of missing values.")
    cat("Input x contains entire column of missing values.")
    Index_missing_1 <- which(colSums(is.na(x)) == nrow(x))    # It counts how many 'NA' are in a column. If the
    # number of NA in a colum is equal to the number of rows
    # then, the condition is met.
    Index_missing_2 <- which(colSums(is.na(x)) == (nrow(x)-1))
    Index_missing <- c(Index_missing_1,Index_missing_2)
    if ((length(Index_missing))==0){
      x_new <- x
    } else {
      x_new <- subset(x,select = -Index_missing)
    }
  } else {x_new <- x}
  
  # Check that DEMEAN is one of 0, 1, 2, 3
  if (!(DEMEAN %in% 0:3)) {
    stop("Input DEMEAN is specified incorrectly.")
  }
  
  # PART 2: SETUP
  
  # Number of observations per series in x_new (i.e. number of rows)
  T <- nrow(x_new)
  
  # Locate missing values in x_new
  x1 <- is.na(x_new)
  
  # Fill in missing values for each series with the unconditional mean of that series.
  # Demean and standardize the updated dataset. Estimate factors using the demeaned and standardized dataset,
  # and use these factors to predict the original dataset.
  
  # Get unconditional mean of the non-missing values of each series
  mut <- matrix(rep(colMeans(x_new, na.rm = TRUE), T), nrow = nrow(x_new), ncol = ncol(x_new), byrow = TRUE)
  
  # Replace missing values with unconditional mean
  x2 <- x_new
  x2[is.na(x2)] <- mut[is.na(x2)]         # we replace the NA values in the vector x2 with the corresponding non-NA
  # values from the vector mut.
  # Check whether there are entire columns of zeros
  Index_zeros <- which(colSums(x2==0) == nrow(x2))
  if ((length(Index_zeros))==0){
    x2_new <- x2
    x1_new <- x1
  } else {
    x2_new <- subset(x2,select = -Index_zeros)
    x1_new <- subset(x1,select = - Index_zeros)
    x_new <- subset(x_new,select = -Index_zeros)
  }
  
  # Number of series in x2_new (i.e. number of columns)
  N <- ncol(x2_new)
  
  # Demean and standardize data
  x3 <- transform_data(x2_new, DEMEAN)
  # Check whether there are entire columns of zeros
  Index_zeros <- which(colSums(x3$x22==0) == nrow(x3$x22))
  if ((length(Index_zeros))==0){
    x22 <- x3$x22
  } else {
    x22 <- subset(x3$x22,select = -Index_zeros)
  }
  
  Z <- as.matrix(x22[1:(nrow(x22)-h),])            # Regressors used for computing the regression coefficients

  
  # Standardize the dependent variable to have mean zero and unitary variance.
  # (Mean and variance will be reattributed to the forecsats, see below)
  Y<-as.matrix(Y[(h+1):length(Y)])
  my = colMeans(Y)
  sy = sd(Y)/sqrt(length(Y))
  Y_std = (Y-my)/sy
  
  b <- solve(t(Z)%*%Z + nu*diag(N)) %*% t(Z) %*% Y_std
  pred <- (tail(Z, 1) %*% b)*sy+my; 
  
#  cv.m <- cv.glmnet(Z,Y_std,alpha=0)
  pred <- predict(cv.m, newx = tail(Z, 1) )
  prediction <- pred*sy+my; 
  
  return(list(pred = pred, beta = b))
}

######################################
#### FUNCTION Lasso_regression ####
######################################
Lasso_regression <- function(yy,x, DEMEAN) {
  # Apply moving average filter: Y = (y_{+1}+...+y_{+h})/h
  Y <- stats::filter(yy, filter = rep(1/h, h), sides = 1)   # Dependent variable
  
  
  # PART 1: CHECKS
  # Check that x is not missing values for an entire row
  if (any(rowSums(is.na(x)) == ncol(x))) {
    stop("Input x contains entire row of missing values.")
  }
  
  # Check that x is not missing values for an entire column
  if (any(colSums(is.na(x)) == nrow(x)) || any(colSums(is.na(x)) == (nrow(x)-1))) {
    #stop("Input x contains entire column of missing values.")
    cat("Input x contains entire column of missing values.")
    Index_missing_1 <- which(colSums(is.na(x)) == nrow(x))    # It counts how many 'NA' are in a column. If the
    # number of NA in a colum is equal to the number of rows
    # then, the condition is met.
    Index_missing_2 <- which(colSums(is.na(x)) == (nrow(x)-1))
    Index_missing <- c(Index_missing_1,Index_missing_2)
    if ((length(Index_missing))==0){
      x_new <- x
    } else {
      x_new <- subset(x,select = -Index_missing)
    }
  } else {x_new <- x}
  
  # Check that DEMEAN is one of 0, 1, 2, 3
  if (!(DEMEAN %in% 0:3)) {
    stop("Input DEMEAN is specified incorrectly.")
  }
  
  # PART 2: SETUP
  
  # Number of observations per series in x_new (i.e. number of rows)
  T <- nrow(x_new)
  
  # Locate missing values in x_new
  x1 <- is.na(x_new)
  
  # Fill in missing values for each series with the unconditional mean of that series.
  # Demean and standardize the updated dataset. Estimate factors using the demeaned and standardized dataset,
  # and use these factors to predict the original dataset.
  
  # Get unconditional mean of the non-missing values of each series
  mut <- matrix(rep(colMeans(x_new, na.rm = TRUE), T), nrow = nrow(x_new), ncol = ncol(x_new), byrow = TRUE)
  
  # Replace missing values with unconditional mean
  x2 <- x_new
  x2[is.na(x2)] <- mut[is.na(x2)]         # we replace the NA values in the vector x2 with the corresponding non-NA
  # values from the vector mut.
  # Check whether there are entire columns of zeros
  Index_zeros <- which(colSums(x2==0) == nrow(x2))
  if ((length(Index_zeros))==0){
    x2_new <- x2
    x1_new <- x1
  } else {
    x2_new <- subset(x2,select = -Index_zeros)
    x1_new <- subset(x1,select = - Index_zeros)
    x_new <- subset(x_new,select = -Index_zeros)
  }
  
  # Number of series in x2_new (i.e. number of columns)
  N <- ncol(x2_new)
  
  # Demean and standardize data
  x3 <- transform_data(x2_new, DEMEAN)
  # Check whether there are entire columns of zeros
  Index_zeros <- which(colSums(x3$x22==0) == nrow(x3$x22))
  if ((length(Index_zeros))==0){
    x22 <- x3$x22
  } else {
    x22 <- subset(x3$x22,select = -Index_zeros)
  }
  
  Z <- as.matrix(x22[1:(nrow(x22)-h),])            # Regressors used for computing the regression coefficients
  
  
  # Standardize the dependent variable to have mean zero and unitary variance.
  # (Mean and variance will be reattributed to the forecsats, see below)
  Y<-as.matrix(Y[(h+1):length(Y)])
  my = colMeans(Y)
  sy = sd(Y)/sqrt(length(Y))
  Y_std = (Y-my)/sy
  cv.m <- cv.glmnet(Z,Y_std,alpha=1)
  pred <- predict(cv.m, newx = tail(Z, 1) )
  prediction <- pred*sy+my; 
  return(list(pred = prediction, beta = cv.m))
}

#### FUNCTION Remove_outliers ####
remove_outliers <- function(X) {
  # =========================================================================
  # DESCRIPTION:
  # This function takes a set of series aligned in the columns of a matrix
  # and replaces outliers with the value NA.
  #
  # -------------------------------------------------------------------------
  # INPUT:
  #           X   = dataset (one series per column)
  #
  # OUTPUT:
  #           Y   = dataset with outliers replaced with NA
  #
  # -------------------------------------------------------------------------
  # NOTES:
  #           1) Outlier definition: a data point x of a series X(:,i) is
  #           considered an outlier if abs(x-median)>10*interquartile_range.
  #
  #           2) This function ignores values of NaN and thus is capable of
  #           replacing outliers for series that have missing values.
  #
  # =========================================================================
  
  # =========================================================================
  # Calculate median of each series
  #             We use the 'apply' function to calculate the median for each
  #             column (i.e., margin 2) of a matrix 'X'
  #             -'X': This is the matrix or data frame for which you want to calculate column-wise medians.
  #             -'2': This argument specifies that the operation should be applied to each column.
  #                 In R, 1 means rows, and 2 means columns.
  #             - stats::median: This is the function that will be applied to each column (or row) of the matrix.
  #               In this case, it's the median function from the stats package.
  #             - na.rm = TRUE: This argument specifies whether to remove missing values (NA) before applying
  #               the function. In this case, na.rm = TRUE means that any missing values in each column will be
  #               ignored when calculating the median.
  #  So, overall, this command is calculating the median of each column in the matrix X, ignoring any missing values
  #  in each column. The result will be a vector of median values, one for each column of the matrix.
  median_X <- apply(X, 2, stats::median, na.rm = TRUE)
  
  # Repeat median of each series over all data points in the series
  median_X_mat <- matrix(rep(median_X, nrow(X)), nrow = nrow(X),
                         ncol = ncol(X), byrow = TRUE)
  #             - rep(median_X, nrow(X)): The rep function is used to replicate the value median_X a certain number
  #               of times. In this case, it is replicated nrow(X) times, where nrow(X) is the number of rows in the
  #               matrix X. This creates a vector of repeated median values.
  #             - matrix(...): This function is then used to convert the repeated median vector into a matrix.
  #                 nrow = nrow(X): Specifies the number of rows in the resulting matrix, which is the same as the
  #                                 number of rows in the original matrix X.
  #                 ncol = ncol(X): Specifies the number of columns in the resulting matrix, which is the same as
  #                                 the number of columns in the original matrix X.
  #                 byrow = TRUE: This argument specifies that the values in the repeated median vector should be
  #                               filled into the matrix by rows. If byrow = FALSE (or not specified), the filling would be done by columns.
  # So, overall, this command creates a matrix where each row contains the same repeated median value, and the
  # number of rows and columns in the new matrix is the same as the number of rows and columns in the original
  # matrix.
  
  # Calculate quartiles
  Q <- apply(X, 2, stats::quantile, probs = c(0.25, 0.75), na.rm = TRUE)
  
  # Calculate interquartile range (IQR) of each series
  IQR <- Q[2,] - Q[1,]
  
  # Repeat IQR of each series over all data points in the series
  IQR_mat <- matrix(rep(IQR, nrow(X)), nrow = nrow(X),
                    ncol = ncol(X), byrow = TRUE)
  
  # Determine outliers
  Z <- abs(X - median_X_mat)
  outlier <- (Z > (10 * IQR_mat))
  
  # Replace outliers with NaN
  Y <- X
  Y[outlier] <- NA
  
  # Cleaned data
  outdata <- Y
  # We set the class attribute of the object outdata to be a combination of two classes: "data.frame" and "fredmd".
  # In R, an object can belong to multiple classes. The class function is used to query or set the class of an object.
  # In this case, it's setting the class of outdata to be both "data.frame" and "fredmd".
  #                               A "data.frame" is a collection of vectors of identical lengths. Each vector 
  #                               represents a column, and each vector can be of a different data type (e.g., 
  #                               characters, integers, factors).
  class(outdata) <- c("data.frame", "fredmd")
  return(outdata)
  
  # Print the number of outliers
  print("Number of outliers:", quote = FALSE)     # quote = FALSE: The quote argument in the print function controls
  # whether or not to print quotation marks around the character
  # string. When quote = FALSE, it means that the string will be
  # printed without quotation marks.
  print(sum(outlier, na.rm = TRUE), quote = FALSE)  # na.rm = TRUE: The na.rm argument is set to TRUE, which means
  # that any missing values (NA) in the vector or matrix will be
  # removed before calculating the sum.
  # If na.rm is set to FALSE or not specified, the presence of any
  # missing values would result in the sum being reported as NA.
}

#### FUNCTION factors_em_2 ####
factors_em_2 <- function(x, kmax, jj, DEMEAN) {
  # PART 1: CHECKS
  
  # Check that x is not missing values for an entire row
  if (any(rowSums(is.na(x)) == ncol(x))) {
    stop("Input x contains entire row of missing values.")
  }
  
  # Check that x is not missing values for an entire column
  if (any(colSums(is.na(x)) == nrow(x))) {
    stop("Input x contains entire column of missing values.")
  }
  
  # Check that kmax is an integer between 1 and the number of columns of x, or 99
  if (!((kmax <= ncol(x) && kmax >= 1 && floor(kmax) == kmax) || kmax == 99)) {
    stop("Input kmax is specified incorrectly.")
  }
  
  # Check that jj is one of 1, 2, 3
  if (!(jj %in% c(1, 2, 3))) {
    stop("Input jj is specified incorrectly.")
  }
  
  # Check that DEMEAN is one of 0, 1, 2, 3
  if (!(DEMEAN %in% 0:3)) {
    stop("Input DEMEAN is specified incorrectly.")
  }
  
  # PART 2: SETUP
  
  # Maximum number of iterations for the EM algorithm
  maxit <- 50
  
  # Number of observations per series in x (i.e. number of rows)
  T <- nrow(x)
  
  # Number of series in x (i.e. number of columns)
  N <- ncol(x)
  
  # Set error to arbitrarily high number
  err <- 999
  
  # Set iteration counter to 0
  it <- 0
  
  # Locate missing values in x
  x1 <- is.na(x)
  
  # PART 3: INITIALIZE EM ALGORITHM
  # Fill in missing values for each series with the unconditional mean of that series.
  # Demean and standardize the updated dataset. Estimate factors using the demeaned and standardized dataset,
  # and use these factors to predict the original dataset.
  
  # Get unconditional mean of the non-missing values of each series
  mut <- matrix(rep(colMeans(x, na.rm = TRUE), T), nrow = nrow(x), ncol = N, byrow = TRUE)
  
  # Replace missing values with unconditional mean
  x2 <- x
  x2[is.na(x)] <- mut[is.na(x)]         # we replace the NA values in the vector x2 with the corresponding non-NA
  # values from the vector mut.
  
  # Demean and standardize data
  x3 <- transform_data(x2, DEMEAN)
  
  # If input 'kmax' is not set to 99, use subfunction baing() to determine
  # the number of factors to estimate. Otherwise, set number of factors equal
  # to 8
  if (kmax != 99) {
    icstar <- baing(x3$x22, kmax, jj)$ic1
  } else {
    icstar <- 8
  }
  
  # Run principal components on updated dataset
  pc_result <- pc2(x3$x22, icstar)
  chat0 <- pc_result$chat
  Fhat <- pc_result$fhat
  lamhat <- pc_result$lambda
  ve2 <- pc_result$ss
  
  # PART 4: PERFORM EM ALGORITHM
  # Update missing values using values predicted by the latest set of factors.
  # Demean and standardize the updated dataset. Estimate a new set of factors using the updated dataset.
  # Repeat the process until the factor estimates do not change.
  
  # Run while error is large and have yet to exceed maximum number of iterations
  while (err > 0.000001 && it < maxit) {
    # INCREASE ITERATION COUNTER
    it <- it + 1
    
    # Display iteration counter, error, and number of factors
    cat(sprintf('Iteration %d: obj %10f IC %d \n', it, err, icstar))
    # The "cat" and "sprintf" functions in R are used for formatting and printing text to the
    # console.
    # "%d": This is a placeholder for an integer.
    # "%10f": This is a placeholder for a floating-point number, with a width of
    # 10 characters, including the decimal point.
    # \n: This is a newline character, which moves the cursor to the next line.
    
    # UPDATE MISSING VALUES
    for (t in 1:T) {
      for (j in 1:N) {
        if (x1[t, j] == 1) {
          x2[t, j] <- chat0[t, j] * x3$sdt[t, j] + x3$mut[t, j]
        } else {
          x2[t, j] <- x[t, j]
        }
      }
    }
    
    # ESTIMATE FACTORS
    # Demean and standardize the new data and recalculate mut and sdt using subfunction "transform_data()"
    #   x3  = transformed dataset
    #   mut = matrix containing the values subtracted from x2 during the transformation
    #   sdt = matrix containing the values that x2 was divided by during the transformation
    x3 <- transform_data(x2, DEMEAN)
    
    # Determine number of factors to estimate for the new dataset using subfunction "baing()"
    # (or set to 8 if kmax equals 99)
    if (kmax != 99) {
      icstar <- baing(x3$x22, kmax, jj)$ic1
    } else {
      icstar <- 8
    }
    
    # Run principal components on the new dataset using subfunction "pc2()"
    #   chat   = values of x22 predicted by the factors
    #   Fhat   = factors scaled by (1/sqrt(N)) where N is the number of
    #            series
    #   lamhat = factor loadings scaled by number of series
    #   ve2    = eigenvalues of x3'*x3
    pc_result <- pc2(x3$x22, icstar)
    chat <- pc_result$chat
    
    # CALCULATE NEW ERROR VALUE
    # Caclulate difference between the predicted values of the new dataset and the predicted values of the previous
    # dataset
    diff <- chat - chat0
    
    # The error value is equal to the sum of the squared differences between "chat" and "chat0" divided by the sum
    # of the squared values of "chat0"
    v1 <- as.vector(diff)
    v2 <- as.vector(chat0)
    err <- sum(v1^2) / sum(v2^2)
    
    # Set chat0 equal to the current chat
    chat0 <- chat
  }
  
  # Produce warning if maximum number of iterations is reached
  if (it == maxit) {
    warning('Maximum number of iterations reached in EM algorithm')
  }
  # Final Output:
  Fhat <- pc_result$fhat
  lamhat <- pc_result$lambda
  ve2 <- pc_result$ss
  
  # FINAL DIFFERENCE
  # Calculate the difference between the initial dataset and the values predicted by the final set of factors
  ehat <- x - chat * x3$sdt - x3$mut
  
  
  return(list(ehat = ehat, Fhat = Fhat, lamhat = lamhat, ve2 = ve2, x2 = x2))
}